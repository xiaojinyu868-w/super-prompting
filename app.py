import streamlit as st
import requests
import json
import time
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®
API_BASE_URL = os.getenv("DEFAULT_API_BASE_URL", "https://api.siliconflow.cn")
DEFAULT_PORT = os.getenv("PORT", "3000")
BACKEND_URL = f"http://localhost:{DEFAULT_PORT}/api"

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="SPO+ å¢å¼ºå‹è‡ªç›‘ç£æç¤ºä¼˜åŒ–ç³»ç»Ÿ",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        margin-bottom: 1rem;
    }
    .output-container {
        background-color: #f0f2f6;
        border-radius: 0.5rem;
        padding: 1rem;
        margin-bottom: 1rem;
    }
    .better {
        border-left: 4px solid #28a745;
    }
    .worse {
        border-left: 4px solid #dc3545;
    }
    .similar {
        border-left: 4px solid #ffc107;
    }
    .history-item {
        padding: 0.5rem;
        margin-bottom: 0.5rem;
        border-radius: 0.3rem;
        background-color: #f8f9fa;
    }
    .history-item.better {
        border-left: 4px solid #28a745;
    }
    .history-item.not-better {
        border-left: 4px solid #dc3545;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'initialized' not in st.session_state:
    st.session_state.initialized = False
    st.session_state.api_configured = False
    st.session_state.current_view = "config"
    st.session_state.current_iteration = 0
    st.session_state.max_iterations = 10
    st.session_state.samples = []
    st.session_state.current_best_prompt = ""
    st.session_state.current_best_outputs = {}
    st.session_state.new_prompt = ""
    st.session_state.new_outputs = {}
    st.session_state.evaluations = {}
    st.session_state.analysis = ""
    st.session_state.optimization_history = []
    st.session_state.is_optimizing = False
    st.session_state.available_models = []

# è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
def get_available_models():
    try:
        response = requests.get(f"{BACKEND_URL}/models")
        if response.status_code == 200:
            data = response.json()
            if data.get('success'):
                return data.get('models', [])
        return []
    except Exception as e:
        st.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
        return []

# è°ƒç”¨API
def call_api(endpoint, data=None):
    try:
        if data:
            response = requests.post(f"{BACKEND_URL}/{endpoint}", json=data)
        else:
            response = requests.get(f"{BACKEND_URL}/{endpoint}")
        
        if response.status_code == 200:
            return response.json()
        else:
            error_data = response.json()
            st.error(f"APIé”™è¯¯: {error_data.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return None
    except Exception as e:
        st.error(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
        return None

# é…ç½®API
def configure_api(api_key, base_url, models):
    data = {
        "apiKey": api_key,
        "baseUrl": base_url,
        "models": models
    }
    
    response = call_api("config", data)
    if response and response.get('success'):
        st.session_state.api_configured = True
        return True
    return False

# ç”Ÿæˆæµ‹è¯•æ ·æœ¬
def generate_samples(task_description):
    data = {
        "taskDescription": task_description
    }
    
    response = call_api("generate-samples", data)
    if response and response.get('success'):
        return response.get('samples', [])
    return []

# æ‰§è¡Œæç¤ºè¯
def execute_prompt(prompt, question):
    data = {
        "prompt": prompt,
        "question": question
    }
    
    response = call_api("execute-prompt", data)
    if response and response.get('success'):
        return response.get('output', "")
    return ""

# ä¼˜åŒ–æç¤ºè¯
def optimize_prompt(current_prompt, current_output, task_description, history=""):
    data = {
        "currentPrompt": current_prompt,
        "currentOutput": current_output,
        "taskDescription": task_description,
        "history": history
    }
    
    response = call_api("optimize-prompt", data)
    if response and response.get('success'):
        return response.get('newPrompt', "")
    return ""

# è¯„ä¼°è¾“å‡º
def evaluate_outputs(output_a, output_b, task_description, question):
    data = {
        "outputA": output_a,
        "outputB": output_b,
        "taskDescription": task_description,
        "question": question
    }
    
    response = call_api("evaluate-outputs", data)
    if response and response.get('success'):
        return response.get('evaluation', "ç›¸ä¼¼")
    return "ç›¸ä¼¼"

# åˆ†ææç¤ºå˜åŒ–
def analyze_changes(old_prompt, new_prompt, task_description):
    data = {
        "oldPrompt": old_prompt,
        "newPrompt": new_prompt,
        "taskDescription": task_description
    }
    
    response = call_api("analyze-changes", data)
    if response and response.get('success'):
        return response.get('analysis', "")
    return ""

# æ‰§è¡Œå½“å‰æœ€ä½³æç¤ºè¯
def run_current_best_prompt():
    outputs = {}
    
    with st.spinner("æ­£åœ¨æ‰§è¡Œå½“å‰æç¤ºè¯..."):
        for sample in st.session_state.samples:
            output = execute_prompt(st.session_state.current_best_prompt, sample['question'])
            outputs[sample['id']] = output
    
    st.session_state.current_best_outputs = outputs
    return outputs

# è·å–ä¼˜åŒ–å†å²æ‘˜è¦
def get_optimization_history_summary():
    if not st.session_state.optimization_history:
        return ""
    
    # åªå–æœ€è¿‘3æ¬¡è¿­ä»£çš„å†å²
    recent_history = st.session_state.optimization_history[-3:]
    
    return "\n".join([
        f"è¿­ä»£{item['iteration']}: {'æ”¹è¿›æˆåŠŸ' if item['is_better'] else 'æœªæ”¹è¿›'}"
        for item in recent_history
    ])

# åˆ¤æ–­æ˜¯å¦åº”è¯¥æ›´æ–°æœ€ä½³æç¤º
def should_update_best_prompt(evaluations):
    better_count = 0
    worse_count = 0
    
    for sample_id, result in evaluations.items():
        if result == "Bæ›´å¥½":
            better_count += 1
        elif result == "Aæ›´å¥½":
            worse_count += 1
    
    # å¦‚æœæœ‰æ›´å¤šæ ·æœ¬è®¤ä¸ºæ–°æç¤ºæ›´å¥½ï¼Œåˆ™æ›´æ–°
    return better_count > worse_count

# è¿è¡Œä¼˜åŒ–æ­¥éª¤
def run_optimization_step():
    if st.session_state.current_iteration >= st.session_state.max_iterations:
        st.session_state.is_optimizing = False
        st.session_state.current_view = "results"
        return
    
    st.session_state.current_iteration += 1
    
    # 1. ç”Ÿæˆæ–°æç¤ºå€™é€‰
    with st.spinner(f"æ­£åœ¨æ‰§è¡Œç¬¬ {st.session_state.current_iteration} æ¬¡ä¼˜åŒ–..."):
        new_prompt = optimize_prompt(
            st.session_state.current_best_prompt,
            json.dumps(st.session_state.current_best_outputs),
            st.session_state.task_description,
            get_optimization_history_summary()
        )
        
        if not new_prompt:
            st.error("ä¼˜åŒ–æç¤ºè¯å¤±è´¥")
            st.session_state.is_optimizing = False
            return
        
        st.session_state.new_prompt = new_prompt
        
        # 2. æ‰§è¡Œæ–°æç¤º
        new_outputs = {}
        for sample in st.session_state.samples:
            output = execute_prompt(new_prompt, sample['question'])
            new_outputs[sample['id']] = output
        
        st.session_state.new_outputs = new_outputs
        
        # 3. è¯„ä¼°æ–°æ—§è¾“å‡º
        evaluations = {}
        for sample in st.session_state.samples:
            sample_id = sample['id']
            output_a = st.session_state.current_best_outputs.get(sample_id, "")
            output_b = new_outputs.get(sample_id, "")
            
            evaluation = evaluate_outputs(
                output_a,
                output_b,
                st.session_state.task_description,
                sample['question']
            )
            
            evaluations[sample_id] = evaluation
        
        st.session_state.evaluations = evaluations
        
        # 4. åˆ†ææç¤ºå˜åŒ–
        analysis = analyze_changes(
            st.session_state.current_best_prompt,
            new_prompt,
            st.session_state.task_description
        )
        
        st.session_state.analysis = analysis
        
        # 5. æ ¹æ®è¯„ä¼°ç»“æœæ›´æ–°æœ€ä½³æç¤º
        is_better = should_update_best_prompt(evaluations)
        if is_better:
            st.session_state.current_best_prompt = new_prompt
            st.session_state.current_best_outputs = new_outputs
        
        # è®°å½•ä¼˜åŒ–å†å²
        st.session_state.optimization_history.append({
            "iteration": st.session_state.current_iteration,
            "prompt": new_prompt,
            "is_better": is_better,
            "analysis": analysis,
            "evaluations": evaluations
        })
    
    # å¦‚æœæ˜¯è‡ªåŠ¨æ¨¡å¼ï¼Œç»§ç»­ä¼˜åŒ–
    if st.session_state.auto_mode:
        time.sleep(1)  # çŸ­æš‚å»¶è¿Ÿï¼Œè®©UIæ›´æ–°
        run_optimization_step()

# é…ç½®è§†å›¾
def show_config_view():
    st.markdown("<h1 class='main-header'>SPO+ å¢å¼ºå‹è‡ªç›‘ç£æç¤ºä¼˜åŒ–ç³»ç»Ÿ</h1>", unsafe_allow_html=True)
    
    # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    if not st.session_state.available_models:
        st.session_state.available_models = get_available_models()
    
    with st.form("config_form"):
        st.markdown("<h2 class='sub-header'>APIè®¾ç½®</h2>", unsafe_allow_html=True)
        
        api_key = st.text_input("API Key", type="password")
        base_url = st.text_input("Base URL", value=API_BASE_URL)
        
        st.markdown("<h2 class='sub-header'>æ¨¡å‹è®¾ç½®</h2>", unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            optimizer_model = st.selectbox(
                "ä¼˜åŒ–æ¨¡å‹ (LLM-1)",
                options=st.session_state.available_models,
                index=0 if st.session_state.available_models else None
            )
            
            evaluator_model = st.selectbox(
                "è¯„ä¼°æ¨¡å‹ (LLM-3)",
                options=st.session_state.available_models,
                index=2 if len(st.session_state.available_models) > 2 else 0
            )
        
        with col2:
            executor_model = st.selectbox(
                "æ‰§è¡Œæ¨¡å‹ (LLM-2)",
                options=st.session_state.available_models,
                index=5 if len(st.session_state.available_models) > 5 else 0
            )
            
            analyzer_model = st.selectbox(
                "åˆ†ææ¨¡å‹ (LLM-4)",
                options=st.session_state.available_models,
                index=1 if len(st.session_state.available_models) > 1 else 0
            )
        
        st.markdown("<h2 class='sub-header'>ä»»åŠ¡è®¾ç½®</h2>", unsafe_allow_html=True)
        
        task_description = st.text_area("ä»»åŠ¡éœ€æ±‚æè¿°", height=100)
        initial_prompt = st.text_area("åˆå§‹æç¤ºè¯", height=150)
        
        col1, col2 = st.columns(2)
        
        with col1:
            max_iterations = st.number_input("æœ€å¤§è¿­ä»£æ¬¡æ•°", min_value=1, max_value=20, value=10)
        
        with col2:
            auto_mode = st.checkbox("è‡ªåŠ¨æ¨¡å¼ (æ— éœ€äººå·¥å¹²é¢„)", value=True)
        
        submitted = st.form_submit_button("å¼€å§‹ä¼˜åŒ–")
        
        if submitted:
            if not api_key:
                st.error("è¯·è¾“å…¥API Key")
                return
            
            if not task_description:
                st.error("è¯·è¾“å…¥ä»»åŠ¡éœ€æ±‚æè¿°")
                return
            
            if not initial_prompt:
                st.error("è¯·è¾“å…¥åˆå§‹æç¤ºè¯")
                return
            
            # é…ç½®æ¨¡å‹
            models = {
                "optimizer": optimizer_model,
                "executor": executor_model,
                "evaluator": evaluator_model,
                "analyzer": analyzer_model
            }
            
            # ä¿å­˜é…ç½®åˆ°ä¼šè¯çŠ¶æ€
            st.session_state.task_description = task_description
            st.session_state.current_best_prompt = initial_prompt
            st.session_state.max_iterations = max_iterations
            st.session_state.auto_mode = auto_mode
            
            # é…ç½®API
            with st.spinner("æ­£åœ¨é…ç½®API..."):
                if configure_api(api_key, base_url, models):
                    st.success("APIé…ç½®æˆåŠŸ")
                    
                    # ç”Ÿæˆæµ‹è¯•æ ·æœ¬
                    with st.spinner("æ­£åœ¨ç”Ÿæˆæµ‹è¯•æ ·æœ¬..."):
                        samples = generate_samples(task_description)
                        
                        if samples:
                            st.session_state.samples = samples
                            
                            # æ‰§è¡Œåˆå§‹æç¤º
                            outputs = run_current_best_prompt()
                            
                            if outputs:
                                st.session_state.initialized = True
                                st.session_state.current_view = "optimization"
                                st.session_state.is_optimizing = True
                                st.rerun()
                        else:
                            st.error("ç”Ÿæˆæµ‹è¯•æ ·æœ¬å¤±è´¥")
                else:
                    st.error("APIé…ç½®å¤±è´¥")

# ä¼˜åŒ–è§†å›¾
def show_optimization_view():
    st.markdown("<h1 class='main-header'>SPO+ ä¼˜åŒ–è¿‡ç¨‹</h1>", unsafe_allow_html=True)
    
    # çŠ¶æ€æ 
    col1, col2, col3 = st.columns([2, 6, 2])
    
    with col1:
        st.markdown(f"**è¿­ä»£è¿›åº¦:** {st.session_state.current_iteration}/{st.session_state.max_iterations}")
    
    with col2:
        progress = st.progress(st.session_state.current_iteration / st.session_state.max_iterations)
    
    with col3:
        if st.session_state.is_optimizing:
            status = "æ­£åœ¨ä¼˜åŒ–..."
        else:
            status = "ç­‰å¾…æ“ä½œ..."
        st.markdown(f"**çŠ¶æ€:** {status}")
    
    # ä¸»è¦å†…å®¹
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("<h2 class='sub-header'>æç¤ºè¯æ¯”è¾ƒ</h2>", unsafe_allow_html=True)
        
        st.markdown("**å½“å‰æœ€ä½³æç¤º**")
        st.text_area("current_best_prompt", value=st.session_state.current_best_prompt, height=200, label_visibility="collapsed")
        
        if st.session_state.new_prompt:
            st.markdown("**æ–°å€™é€‰æç¤º**")
            st.text_area("new_prompt", value=st.session_state.new_prompt, height=200, label_visibility="collapsed")
        
        if st.session_state.analysis:
            st.markdown("<h2 class='sub-header'>æ”¹è¿›åˆ†æ</h2>", unsafe_allow_html=True)
            st.markdown(st.session_state.analysis)
        
        # æ§åˆ¶æŒ‰é’®
        if not st.session_state.is_optimizing:
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ç»§ç»­ä¼˜åŒ–", key="continue_btn"):
                    st.session_state.is_optimizing = True
                    run_optimization_step()
                    st.rerun()
            
            with col2:
                if st.button("å®Œæˆä¼˜åŒ–", key="finish_btn"):
                    st.session_state.current_view = "results"
                    st.rerun()
    
    with col2:
        st.markdown("<h2 class='sub-header'>æµ‹è¯•æ ·æœ¬</h2>", unsafe_allow_html=True)
        
        # æ˜¾ç¤ºæ ·æœ¬å’Œè¾“å‡º
        for sample in st.session_state.samples:
            sample_id = sample['id']
            
            with st.expander(f"æ ·æœ¬ {sample_id}: {sample['question'][:50]}...", expanded=True):
                st.markdown(f"**é—®é¢˜:** {sample['question']}")
                
                if sample_id in st.session_state.current_best_outputs:
                    st.markdown("**å½“å‰è¾“å‡º:**")
                    current_output = st.session_state.current_best_outputs[sample_id]
                    st.markdown(f"<div class='output-container'>{current_output}</div>", unsafe_allow_html=True)
                
                if st.session_state.new_outputs and sample_id in st.session_state.new_outputs:
                    st.markdown("**æ–°è¾“å‡º:**")
                    new_output = st.session_state.new_outputs[sample_id]
                    
                    # æ·»åŠ è¯„ä¼°ç»“æœæ ·å¼
                    css_class = ""
                    if st.session_state.evaluations and sample_id in st.session_state.evaluations:
                        result = st.session_state.evaluations[sample_id]
                        if result == "Bæ›´å¥½":
                            css_class = "better"
                        elif result == "Aæ›´å¥½":
                            css_class = "worse"
                        else:
                            css_class = "similar"
                    
                    st.markdown(f"<div class='output-container {css_class}'>{new_output}</div>", unsafe_allow_html=True)
                    
                    if st.session_state.evaluations and sample_id in st.session_state.evaluations:
                        result = st.session_state.evaluations[sample_id]
                        st.markdown(f"**è¯„ä¼°ç»“æœ:** {result}")
        
        # ä¼˜åŒ–å†å²
        if st.session_state.optimization_history:
            st.markdown("<h2 class='sub-header'>ä¼˜åŒ–å†å²</h2>", unsafe_allow_html=True)
            
            for item in st.session_state.optimization_history:
                css_class = "better" if item["is_better"] else "not-better"
                
                with st.expander(f"è¿­ä»£ {item['iteration']} - {'æ”¹è¿›æˆåŠŸ' if item['is_better'] else 'æœªæ”¹è¿›'}", expanded=False):
                    st.markdown(f"**æç¤ºè¯:**")
                    st.text_area(f"prompt_{item['iteration']}", value=item['prompt'], height=100, label_visibility="collapsed")
                    
                    st.markdown("**è¯„ä¼°ç»“æœ:**")
                    for sample_id, result in item['evaluations'].items():
                        st.markdown(f"- æ ·æœ¬ {sample_id}: {result}")
                    
                    st.markdown("**åˆ†æ:**")
                    st.markdown(item['analysis'])
        
        # å¦‚æœæ˜¯è‡ªåŠ¨æ¨¡å¼ä¸”æ­£åœ¨ä¼˜åŒ–ï¼Œè‡ªåŠ¨è§¦å‘ä¸‹ä¸€æ­¥
        if st.session_state.auto_mode and st.session_state.is_optimizing and st.session_state.current_iteration > 0:
            run_optimization_step()
            st.rerun()

# ç»“æœè§†å›¾
def show_results_view():
    st.markdown("<h1 class='main-header'>SPO+ ä¼˜åŒ–ç»“æœ</h1>", unsafe_allow_html=True)
    
    # ç»“æœæ‘˜è¦
    st.markdown("<h2 class='sub-header'>ä¼˜åŒ–æ‘˜è¦</h2>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("æ€»è¿­ä»£æ¬¡æ•°", st.session_state.current_iteration)
    
    with col2:
        better_count = sum(1 for item in st.session_state.optimization_history if item["is_better"])
        st.metric("æˆåŠŸæ”¹è¿›æ¬¡æ•°", better_count)
    
    with col3:
        improvement_rate = better_count / st.session_state.current_iteration if st.session_state.current_iteration > 0 else 0
        st.metric("æ”¹è¿›æˆåŠŸç‡", f"{improvement_rate:.0%}")
    
    # æœ€ç»ˆæç¤ºè¯
    st.markdown("<h2 class='sub-header'>æœ€ç»ˆä¼˜åŒ–æç¤ºè¯</h2>", unsafe_allow_html=True)
    
    final_prompt = st.text_area("final_prompt", value=st.session_state.current_best_prompt, height=300, label_visibility="collapsed")
    
    if st.button("å¤åˆ¶æç¤ºè¯"):
        st.code(st.session_state.current_best_prompt)
        st.success("æç¤ºè¯å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼ˆå¯ä»¥é€šè¿‡ä¸Šæ–¹ä»£ç å—å¤åˆ¶ï¼‰")
    
    # ä¼˜åŒ–å†å²
    if st.session_state.optimization_history:
        st.markdown("<h2 class='sub-header'>ä¼˜åŒ–å†å²</h2>", unsafe_allow_html=True)
        
        for item in st.session_state.optimization_history:
            css_class = "better" if item["is_better"] else "not-better"
            
            with st.expander(f"è¿­ä»£ {item['iteration']} - {'æ”¹è¿›æˆåŠŸ' if item['is_better'] else 'æœªæ”¹è¿›'}", expanded=False):
                st.markdown(f"**æç¤ºè¯:**")
                st.text_area(f"result_prompt_{item['iteration']}", value=item['prompt'], height=100, label_visibility="collapsed")
                
                st.markdown("**è¯„ä¼°ç»“æœ:**")
                for sample_id, result in item['evaluations'].items():
                    st.markdown(f"- æ ·æœ¬ {sample_id}: {result}")
                
                st.markdown("**åˆ†æ:**")
                st.markdown(item['analysis'])
    
    # å¯¼å‡ºå’Œé‡ç½®æŒ‰é’®
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("å¯¼å‡ºå†å²"):
            export_data = {
                "date": time.strftime("%Y-%m-%d %H:%M:%S"),
                "task_description": st.session_state.task_description,
                "initial_prompt": st.session_state.current_best_prompt,
                "iterations": st.session_state.current_iteration,
                "history": [{
                    "iteration": item["iteration"],
                    "prompt": item["prompt"],
                    "is_better": item["is_better"],
                    "analysis": item["analysis"]
                } for item in st.session_state.optimization_history]
            }
            
            st.download_button(
                label="ä¸‹è½½JSONæ–‡ä»¶",
                data=json.dumps(export_data, ensure_ascii=False, indent=2),
                file_name=f"spo-plus-history-{time.strftime('%Y%m%d-%H%M%S')}.json",
                mime="application/json"
            )
    
    with col2:
        if st.button("å¼€å§‹æ–°çš„ä¼˜åŒ–"):
            # é‡ç½®ä¼šè¯çŠ¶æ€
            for key in list(st.session_state.keys()):
                if key != "available_models":
                    del st.session_state[key]
            
            st.session_state.initialized = False
            st.session_state.api_configured = False
            st.session_state.current_view = "config"
            st.session_state.current_iteration = 0
            st.session_state.max_iterations = 10
            st.session_state.samples = []
            st.session_state.current_best_prompt = ""
            st.session_state.current_best_outputs = {}
            st.session_state.new_prompt = ""
            st.session_state.new_outputs = {}
            st.session_state.evaluations = {}
            st.session_state.analysis = ""
            st.session_state.optimization_history = []
            st.session_state.is_optimizing = False
            
            st.rerun()

# ä¸»åº”ç”¨
def main():
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.image("https://raw.githubusercontent.com/streamlit/streamlit/master/examples/data/logo.jpg", width=100)
        st.markdown("# SPO+")
        st.markdown("å¢å¼ºå‹è‡ªç›‘ç£æç¤ºä¼˜åŒ–ç³»ç»Ÿ")
        
        st.markdown("---")
        
        if st.button("é…ç½®"):
            st.session_state.current_view = "config"
            st.rerun()
        
        if st.session_state.initialized:
            if st.button("ä¼˜åŒ–è¿‡ç¨‹"):
                st.session_state.current_view = "optimization"
                st.rerun()
            
            if st.button("ä¼˜åŒ–ç»“æœ"):
                st.session_state.current_view = "results"
                st.rerun()
        
        st.markdown("---")
        st.markdown("### å…³äº")
        st.markdown("""
        SPO+æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æç¤ºè¯ä¼˜åŒ–ç³»ç»Ÿï¼Œç»“åˆäº†è‡ªåŠ¨åŒ–ä¼˜åŒ–å’Œäººç±»åé¦ˆï¼Œå¸®åŠ©ç”¨æˆ·åˆ›å»ºæ›´é«˜è´¨é‡çš„æç¤ºè¯ã€‚
        
        **ç‰¹ç‚¹:**
        - è‡ªåŠ¨ä¼˜åŒ–
        - æµå¼è¾“å‡º
        - äººæœºåä½œ
        - å¯è§†åŒ–ç•Œé¢
        """)
    
    # ä¸»å†…å®¹
    if st.session_state.current_view == "config":
        show_config_view()
    elif st.session_state.current_view == "optimization":
        show_optimization_view()
    elif st.session_state.current_view == "results":
        show_results_view()

if __name__ == "__main__":
    main() 